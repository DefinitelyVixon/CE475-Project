{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "error_calculation_metrics = ['mean_squared_error', 'mean_absolute_error']\n",
    "ecm = error_calculation_metrics[1]\n",
    "k_fold_value = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before applying any machine learning algorithms, I wanted to see how each of the given predictors relate to each other.\n",
    "To do it, I have found out pairplot() function from seaborn library which takes the name of columns (predictors) as\n",
    "parameters and plots each one of them with another."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "raw_dataset = pd.read_csv('dataset_v1.csv', sep=',', skipinitialspace=True)\n",
    "dataset = raw_dataset.copy()\n",
    "predict_set = dataset.tail(20)\n",
    "dataset = dataset.drop(predict_set.index)\n",
    "\n",
    "predictors = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6']\n",
    "\n",
    "def random_sample(train_fraction):\n",
    "    train = dataset.sample(frac=train_fraction, random_state=0)\n",
    "    test = dataset.drop(train.index)\n",
    "    return train, test\n",
    "\n",
    "def k_fold_sample():\n",
    "    kf = KFold(n_splits=k_fold_value, random_state=None, shuffle=False)\n",
    "\n",
    "    features = np.array(dataset[predictors])\n",
    "    labels = np.array(dataset['Y'])\n",
    "\n",
    "    k_s = []\n",
    "    for train_i, test_i in kf.split(dataset):\n",
    "        k_s.append({'train_features': features[train_i],\n",
    "                          'train_labels': labels[train_i],\n",
    "                          'test_features': features[test_i],\n",
    "                          'test_labels': labels[test_i]})\n",
    "    return k_s\n",
    "\n",
    "train_set, test_set = random_sample(train_fraction=0.8)\n",
    "k_samples = k_fold_sample()\n",
    "\n",
    "sns.pairplot(train_set[['x1', 'x2', 'x3', 'x4', 'x5', 'x6']], diag_kind='kde')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From looking at the results, it is clear that x1 and x6 values are exactly the same. So, I have decided to drop x6\n",
    "predictor since we do not need the same value twice.\n",
    "\n",
    "Then, I wanted to see how each of those predictors relate to Y separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = dataset.drop('x6', axis=1)\n",
    "train_set = train_set.drop('x6', axis=1)\n",
    "test_set = test_set.drop('x6', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictors = ['x1', 'x2', 'x3', 'x4', 'x5']\n",
    "\n",
    "fig_, axes_ = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes_[1][2].set_visible(False)\n",
    "axes_[1][0].set_position([0.24, 0.125, 0.228, 0.343])\n",
    "axes_[1][1].set_position([0.55, 0.125, 0.228, 0.343])\n",
    "[sns.scatterplot(ax=axes_[i // 3, i % 3], x=dataset[predictors[i]], y=dataset['Y'], alpha=0.5, color='b')\n",
    " for i in range(len(predictors))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From here, I can see that when x1 has low values, their corresponding Y values are also tend to be low. Similarly,\n",
    "when x5 has a value greater than 5, its corresponding Y value is very low.\n",
    "\n",
    "The problem is, \"very low\" does not provide a clear metric,\n",
    "so I have decided to examine \"low\" and \"high\" Y values separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "plt.setp(axes, xticks=np.arange(0, 100, 5))\n",
    "\n",
    "limit = 50\n",
    "lt_limit = train_set.copy()\n",
    "lt_limit.drop(lt_limit[lt_limit['Y'] <= limit].index, inplace=True)\n",
    "gt_limit = train_set.copy()\n",
    "gt_limit.drop(gt_limit[gt_limit['Y'] > limit].index, inplace=True)\n",
    "\n",
    "sns.scatterplot(ax=axes[0], x=lt_limit['SampleNo'], y=lt_limit['Y'])\n",
    "sns.scatterplot(ax=axes[1], x=gt_limit['SampleNo'], y=gt_limit['Y'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Separating points with Y values that are less than 50 from those are greater than 50 give those plots. It is not clear\n",
    "that which model would fit those points the best, but it would be odd if it was that easy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_features = train_set.copy()\n",
    "test_features = test_set.copy()\n",
    "\n",
    "train_labels = train_features.pop('Y')\n",
    "test_labels = test_features.pop('Y')\n",
    "\n",
    "table_heuristics = dataset.describe().transpose()[['min', 'max', 'mean', 'std']]\n",
    "display(table_heuristics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I. Single Linear Regression\n",
    "\n",
    "## I.I. For x1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x1 = np.array(train_features['x1'])\n",
    "x1_normalizer = layers.Normalization(input_shape=[1, ], axis=None)\n",
    "x1_normalizer.adapt(x1)\n",
    "\n",
    "x1_model = tf.keras.Sequential([x1_normalizer, layers.Dense(units=1)])\n",
    "\n",
    "display(x1_model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x1_model.predict(x1)\n",
    "x1_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss=ecm)\n",
    "\n",
    "history = x1_model.fit(x=train_features['x1'],\n",
    "                       y=train_labels,\n",
    "                       epochs=200,\n",
    "                       verbose=0,\n",
    "                       validation_split=0.2)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "display(hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([table_heuristics['min']['x1'], table_heuristics['max']['x1']])\n",
    "\n",
    "sns.scatterplot(ax=ax, x=test_features['x1'], y=test_labels,\n",
    "                alpha=0.7, color='b', label='Test Data')\n",
    "sns.scatterplot(ax=ax, x=train_features['x1'], y=train_labels,\n",
    "                alpha=0.3, color='g', label='Training Data')\n",
    "\n",
    "x = test_features['x1']\n",
    "y_predict = x1_model.predict(x, verbose=0)\n",
    "\n",
    "sns.regplot(ax=ax, x=test_features['x1'], y=y_predict[:,0],\n",
    "            color='r', scatter=False, truncate=False, label='Predicted')\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## I.II. For Every Input Predictor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes[1][2].set_visible(False)\n",
    "axes[1][0].set_position([0.24, 0.125, 0.228, 0.343])\n",
    "axes[1][1].set_position([0.55, 0.125, 0.228, 0.343])\n",
    "\n",
    "all_test_results = {}\n",
    "\n",
    "ax_i = 0\n",
    "xi_normalizer = layers.Normalization(input_shape=[1, ], axis=None)\n",
    "\n",
    "for p in predictors:\n",
    "    ax = axes[ax_i // 3, ax_i % 3]\n",
    "\n",
    "    xi = np.array(train_features[p])\n",
    "    xi_normalizer.adapt(xi)\n",
    "\n",
    "    xi_model = tf.keras.Sequential([xi_normalizer, layers.Dense(units=1)])\n",
    "    xi_model.predict(xi, verbose=0)\n",
    "    xi_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss=ecm)\n",
    "\n",
    "    all_test_results[p] = xi_model.evaluate(test_features[p], test_labels, verbose=0)\n",
    "\n",
    "    x = test_features[p]\n",
    "    y_predict = xi_model.predict(x, verbose=0)\n",
    "\n",
    "    sns.scatterplot(ax=ax, x=test_features[p], y=test_labels,\n",
    "                    alpha=0.7, color='b', label='Test Data')\n",
    "    sns.scatterplot(ax=ax, x=train_features[p], y=train_labels,\n",
    "                    alpha=0.3, color='g', label='Training Data')\n",
    "    sns.regplot(ax=ax, x=x, y=y_predict,\n",
    "                color='r', scatter=False, label='Predicted Y', truncate=False)\n",
    "    ax.set_xlim(table_heuristics['min'][p], table_heuristics['max'][p])\n",
    "    ax.set_xlabel(p)\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.legend()\n",
    "    ax_i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## II. Multiple Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mul_linreg = tf.keras.Sequential([tf.keras.layers.Normalization(axis=-1), layers.Dense(units=1)])\n",
    "\n",
    "mul_linreg.compile(optimizer=tf.optimizers.Adam(learning_rate=0.02), loss=ecm)\n",
    "\n",
    "history = mul_linreg.fit(\n",
    "    train_features[predictors],\n",
    "    train_labels,\n",
    "    epochs=1000,\n",
    "    verbose=0,\n",
    "    validation_split=0.2)\n",
    "\n",
    "all_test_results['mul_linreg'] = mul_linreg.evaluate(test_features[predictors], test_labels, verbose=0)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "display(hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<pre style=\"text-decoration: line-through\"><b>Doesn't Make Sense</b>\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([0,100])\n",
    "\n",
    "sns.scatterplot(ax=ax, x=test_features['SampleNo'], y=test_labels, alpha=0.7, color='b', label='Test Data')\n",
    "sns.scatterplot(ax=ax, x=train_features['SampleNo'], y=train_labels, alpha=0.3, color='g', label='Training Data')\n",
    "\n",
    "y_predict = mul_linreg.predict(test_features[predictors])\n",
    "y_comparison = pd.DataFrame({'Predicted': y_predict[:,0], 'Actual': test_labels})\n",
    "\n",
    "display(y_comparison.transpose())\n",
    "\n",
    "sns.regplot(ax=ax, x=y_comparison.index, y=y_comparison['Predicted'], color='r', scatter=False, truncate=False, label='Predicted')\n",
    "\n",
    "ax.set_xlabel('SampleNo')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "</pre>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_error_table():\n",
    "    display(pd.DataFrame([[k, v] for k,v in all_test_results.items()], columns=['model', ecm]))\n",
    "\n",
    "display_error_table()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# III. Polynomial Regression\n",
    "\n",
    "## III.I. Second Order Polynomial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sec_order_polyreg = tf.keras.Sequential([tf.keras.layers.Normalization(axis=-1), layers.Dense(units=1, input_shape=[3])])\n",
    "\n",
    "sec_order_polyreg.compile(optimizer=tf.optimizers.Adam(learning_rate=0.02), loss=ecm)\n",
    "\n",
    "history = sec_order_polyreg.fit(\n",
    "    train_features[predictors],\n",
    "    train_labels,\n",
    "    epochs=1000,\n",
    "    verbose=0,\n",
    "    validation_split=0.2)\n",
    "\n",
    "all_test_results['sec_order_polyreg'] = sec_order_polyreg.evaluate(test_features[predictors], test_labels, verbose=0)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "display(hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<pre style=\"text-decoration: line-through\"><b>Doesn't Make Sense</b>\n",
    "y_predict = sec_order_polyreg.predict(test_features[predictors])\n",
    "pred_results = pd.DataFrame({'Predicted': y_predict[:, 0], 'SampleNo': test_features['SampleNo']})\n",
    "\n",
    "display(pred_results.transpose())\n",
    "\n",
    "fig = sns.lmplot(data=pred_results, x='SampleNo', y='Predicted', order=2, scatter=False, truncate=False)\n",
    "fig.set(xlim=(0, 100))\n",
    "\n",
    "sns.scatterplot(x=test_features['SampleNo'], y=test_labels, alpha=0.7, color='b', label='Test Data')\n",
    "sns.scatterplot(x=train_features['SampleNo'], y=train_labels, alpha=0.3, color='g', label='Training Data')\n",
    "\n",
    "ax.set_xlabel('SampleNo')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "</pre>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III.II. Third Order Polynomial"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thr_order_polyreg = tf.keras.Sequential([tf.keras.layers.Normalization(axis=-1), layers.Dense(units=1, input_shape=[4])])\n",
    "\n",
    "thr_order_polyreg.compile(optimizer=tf.optimizers.Adam(learning_rate=0.02), loss=ecm)\n",
    "\n",
    "history = thr_order_polyreg.fit(\n",
    "    train_features[predictors],\n",
    "    train_labels,\n",
    "    epochs=1000,\n",
    "    verbose=0,\n",
    "    validation_split=0.2)\n",
    "\n",
    "all_test_results['thr_order_polyreg'] = thr_order_polyreg.evaluate(test_features[predictors], test_labels, verbose=0)\n",
    "\n",
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "display(hist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<pre style=\"text-decoration: line-through\"><b>Doesn't Make Sense</b>\n",
    "y_predict = thr_order_polyreg.predict(test_features[predictors])\n",
    "pred_results = pd.DataFrame({'Predicted': y_predict[:, 0], 'SampleNo': test_features['SampleNo']})\n",
    "\n",
    "display(pred_results.transpose())\n",
    "\n",
    "fig = sns.lmplot(data=pred_results, x='SampleNo', y='Predicted', order=3, scatter=False, truncate=False)\n",
    "fig.set(xlim=(0, 100))\n",
    "\n",
    "sns.scatterplot(x=test_features['SampleNo'], y=test_labels, alpha=0.7, color='b', label='Test Data')\n",
    "sns.scatterplot(x=train_features['SampleNo'], y=train_labels, alpha=0.3, color='g', label='Training Data')\n",
    "\n",
    "ax.set_xlabel('SampleNo')\n",
    "ax.set_ylabel('Y')\n",
    "ax.legend()\n",
    "</pre>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_error_table()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def k_nearest_regression(k=3):\n",
    "\n",
    "    def euclidean_dist(p_x, p_y):\n",
    "        distances = list(map(lambda pr: (p_x[pr] - p_y[pr]) ** 2, predictors))\n",
    "        return sum(distances)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(test_features.index)):\n",
    "        current_row = test_features.iloc[i]\n",
    "        current_distances = [[train_labels.iloc[n], euclidean_dist(current_row, train_features.iloc[n])]\n",
    "                             for n in range(len(train_features.index))]\n",
    "        current_distances.sort(key=lambda n: n[1])\n",
    "        k_nearest_avg = sum([n[0] for n in current_distances[:k]]) // k\n",
    "        predictions.append(k_nearest_avg)\n",
    "\n",
    "    y_comparison = {'actual': list(test_labels), 'predicted': predictions}\n",
    "\n",
    "    k_error = 0\n",
    "    for act, pred in zip(y_comparison['actual'], y_comparison['predicted']):\n",
    "        k_error += abs(act - pred)\n",
    "\n",
    "    return {'k': k, 'comparison': pd.DataFrame(y_comparison).transpose(), 'error': k_error/len(predictions)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IV. K-Nearest-Neighbor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_args = [2, 3, 4, 5]\n",
    "\n",
    "k_nearest_results = [k_nearest_regression(k) for k in knn_args]\n",
    "for knn_result in k_nearest_results:\n",
    "    all_test_results[f'knn_(k={knn_result[\"k\"]})'] = knn_result['error']\n",
    "\n",
    "display_error_table()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TESTING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def calculate_mae(y_act, y_pred):\n",
    "    test_error = 0\n",
    "    for actual, predicted in zip(y_act, y_pred):\n",
    "        test_error += abs(actual - predicted)\n",
    "    return test_error/len(y_pred)\n",
    "\n",
    "def calculate_rmse(y_act, y_pred):\n",
    "    return np.sqrt(((y_act - y_pred) ** 2).sum()/len(predictions))\n",
    "\n",
    "def log_reg():\n",
    "    logistic_regression = LogisticRegression(max_iter=20000)\n",
    "    logistic_regression.fit(train_features[predictors], train_labels)\n",
    "\n",
    "    predictions = logistic_regression.predict(test_features[predictors])\n",
    "    mae_error = calculate_mae(list(test_labels), predictions)\n",
    "\n",
    "    y_comparison = {'actual': list(test_labels), 'predicted': predictions}\n",
    "    return {'comparison': pd.DataFrame(y_comparison), 'error': mae_error}\n",
    "\n",
    "results = log_reg()\n",
    "display(results['comparison'].transpose())\n",
    "all_test_results['log_reg'] = results['error']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display_error_table()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def polynomial_regression(order=2):\n",
    "    poly_features = PolynomialFeatures(degree=order, include_bias=False)\n",
    "    poly_train_features = poly_features.fit_transform(train_features[predictors])\n",
    "\n",
    "    poly_reg_model = LinearRegression()\n",
    "    poly_reg_model.fit(poly_train_features, train_labels)\n",
    "\n",
    "    predictions = poly_reg_model.predict(poly_features.fit_transform(test_features[predictors]))\n",
    "\n",
    "    mae_error = calculate_mae(list(test_labels), predictions)\n",
    "    print(mae_error)\n",
    "\n",
    "polynomial_regression(order=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_mae_avg = 0\n",
    "k_rmse_avg = 0\n",
    "\n",
    "for i in range(len(k_samples)):\n",
    "\n",
    "    lin_reg = LinearRegression().fit(k_samples[i]['train_features'], k_samples[i]['train_labels'])\n",
    "    predictions = lin_reg.predict(k_samples[i]['test_features'])\n",
    "\n",
    "    k_rmse_avg += calculate_rmse(y_act=k_samples[i]['test_labels'], y_pred=predictions)\n",
    "    k_mae_avg += calculate_mae(y_act=k_samples[i]['test_labels'], y_pred=predictions)\n",
    "\n",
    "print(k_rmse_avg/len(k_samples))\n",
    "print(k_mae_avg/len(k_samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}